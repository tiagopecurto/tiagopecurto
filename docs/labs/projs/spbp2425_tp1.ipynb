{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiagopecurto/tiagopecurto/blob/main/docs/labs/projs/spbp2425_tp1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgFZlT_g8O1Y"
      },
      "source": [
        "# Sistemas para Processamento de Big Data\n",
        "## TP1 - Energy Meter Monitoring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The sensor data corresponds to regular readings from 11 residential energy meters. The data covers the month of February 2024.\n",
        "\n",
        "Each data sample has the following schema:\n",
        "\n",
        "timestamp | sensor_id | energy\n",
        "----------|-------------|-----------\n",
        "timestamp | string  | float\n",
        "\n",
        "Each energy value (KWh) corresponds to the accumulated value of the meter at the time of measurement. As such,\n",
        "each meter is expected to produce a monotonically increasing series of pairs of timestamp and energy consummed up to that moment.\n",
        "\n",
        "The meters do not start at zero or at the same value.\n"
      ],
      "metadata": {
        "id": "IRDJq9dL0GWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions\n",
        "\n",
        "The following questions should be answered for the month of February and only for this month.\n",
        "\n",
        "### For the group of sensors:\n",
        "\n",
        "1. Compute the total energy consumed.\n",
        "\n",
        "2. Compute the running total energy consumed so far for each day, inclusive.\n",
        "\n",
        "Note: You can approximate the result but using the last reading of each day from each sensor.\n",
        "\n",
        "### For each sensor, separately:\n",
        "\n",
        "3. Compute the total energy consumed and the average energy consumption per day.\n",
        "\n",
        "4. Compute the day of the month with minimum and maximum energy consumption.\n",
        "\n",
        "Note: You can approximate the result but using the last reading of each day from each sensor.\n",
        "\n",
        "### For each sensor, separately, with estimations:\n",
        "\n",
        "**Assumptions:**\n",
        "\n",
        "+ Readings may be missing for extended periods due to communication problems with the sensors.\n",
        "\n",
        "+ Readings are collected do not fall precisely \"on the hour\". The are collected and recorded any time.\n",
        "\n",
        "+ For more precise results, estimate the value of the meter at precise timestamp, using linear interpolation from nearest readings.\n",
        "\n",
        "5. Compute the **estimated** value of each sensor meter for every hour and day of the month (in ascending order).\n",
        "\n",
        "6. Compute the **estimated** running total of the energy consumed so far. The value should be updated every hour."
      ],
      "metadata": {
        "id": "HC6tMDOU7Fdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requeriments\n",
        "\n",
        "Solve each question using Structured Spark, either Dataframes or SQL or both."
      ],
      "metadata": {
        "id": "kdTj-7SD-67o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Grading Criteria\n",
        "\n",
        "+ Grading will also take into account the general clarity of the programming and of the presentation report (notebook).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qN2ogthr_EIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deadline\n",
        "+ November 10, 23h59\n",
        "\n",
        "For each day late, ***0.5 / day penalty***. Penalty accumulates until the grade of the assignment reaches 8.0."
      ],
      "metadata": {
        "id": "8M6lYfT_BpAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Colab Setup\n"
      ],
      "metadata": {
        "id": "81dR9BTgBg1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install PySpark\n",
        "!pip install pyspark findspark --quiet"
      ],
      "metadata": {
        "id": "L2O_3I3x1dbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619bf040-719b-4a0e-ed60-b925f43925e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the dataset\n",
        "\n",
        "!wget -q -O energy-readings.csv https://raw.githubusercontent.com/smduarte/spbd-2425/refs/heads/main/docs/labs/projs/energy-readings.csv\n",
        "!head -2 energy-readings.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB8R09NjYJUW",
        "outputId": "03f27494-f571-488b-ac15-87822643e9cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date;sensor;energy\n",
            "2024-02-01 00:00:00;D;2615.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]') \\\n",
        "\t\t\t\t\t\t.appName('energy').getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "try :\n",
        "    readings = spark.read.csv('energy-readings.csv',\n",
        "                             sep =';', header=True, inferSchema=True)\n",
        "\n",
        "    readings.printSchema()\n",
        "\n",
        "    #0.Filtra os dados para manter apenas o mês de fevereiro de 2024\n",
        "    readings_february = readings.filter((month(\"date\") == 2) & (year(\"date\") == 2024))\n",
        "      #readings_february.show()\n",
        "\n",
        "    #1.Total energy consumed in February\n",
        "    total_energy_consumed = readings_february.groupBy(\"sensor\") \\\n",
        "      .agg((max(\"energy\")-min(\"energy\")).alias(\"energy_consumed_per_sensor\")) \\\n",
        "      .agg(sum(\"energy_consumed_per_sensor\").alias(\"total_energy_consumed\"))\n",
        "      #total_energy_consumed.show()\n",
        "\n",
        "    #2.Total energy consumed by day in February\n",
        "    #2.1: Calcula o consumo diário de cada sensor\n",
        "    daily_consumption_per_sensor = readings_february.withColumn(\"day\", to_date(\"date\")) \\\n",
        "      .groupBy(\"day\", \"sensor\") \\\n",
        "      .agg((max(\"energy\") - min(\"energy\")).alias(\"daily_consumption\")) \\\n",
        "      .orderBy(\"day\", \"sensor\")\n",
        "    daily_consumption_per_sensor.show()\n",
        "\n",
        "    #2.2: Soma o consumo diário para todos os sensores por dia\n",
        "    total_daily_consumption = daily_consumption_per_sensor.groupBy(\"day\") \\\n",
        "      .agg(sum(\"daily_consumption\").alias(\"total_daily_consumption\")) \\\n",
        "      .orderBy(\"day\")\n",
        "    total_daily_consumption.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #readings.show(5)\n",
        "except Exception as err:\n",
        "    print(err)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo41adHJYGs6",
        "outputId": "45960d31-f7f6-41db-a9e0-5654ef8f2950"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- date: timestamp (nullable = true)\n",
            " |-- sensor: string (nullable = true)\n",
            " |-- energy: double (nullable = true)\n",
            "\n",
            "+----------+------+------------------+\n",
            "|       day|sensor| daily_consumption|\n",
            "+----------+------+------------------+\n",
            "|2024-02-01|     A| 8.100000000000023|\n",
            "|2024-02-01|     B|4.2000000000000455|\n",
            "|2024-02-01|     C| 9.700000000000045|\n",
            "|2024-02-01|     D|12.900000000000091|\n",
            "|2024-02-01|     E| 16.09999999999991|\n",
            "|2024-02-01|     F|              11.0|\n",
            "|2024-02-01|     G|3.2999999999999545|\n",
            "|2024-02-01|     H|              23.5|\n",
            "|2024-02-01|     I|19.899999999999977|\n",
            "|2024-02-01|     J| 2.599999999999909|\n",
            "|2024-02-01|     K| 8.399999999999977|\n",
            "|2024-02-02|     A|4.7999999999999545|\n",
            "|2024-02-02|     B| 4.599999999999909|\n",
            "|2024-02-02|     C| 1.599999999999909|\n",
            "|2024-02-02|     D| 5.900000000000091|\n",
            "|2024-02-02|     E|10.099999999999909|\n",
            "|2024-02-02|     F|               6.5|\n",
            "|2024-02-02|     G| 4.100000000000023|\n",
            "|2024-02-02|     H| 6.199999999999818|\n",
            "|2024-02-02|     I|              12.5|\n",
            "+----------+------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+----------+-----------------------+\n",
            "|       day|total_daily_consumption|\n",
            "+----------+-----------------------+\n",
            "|2024-02-01|     119.69999999999993|\n",
            "|2024-02-02|      69.59999999999957|\n",
            "|2024-02-09|      55.70000000000027|\n",
            "|2024-02-10|     113.90000000000009|\n",
            "|2024-02-11|     117.70000000000027|\n",
            "|2024-02-12|     110.50000000000011|\n",
            "|2024-02-13|     112.49999999999989|\n",
            "|2024-02-14|      92.89999999999964|\n",
            "|2024-02-15|      81.00000000000045|\n",
            "|2024-02-16|     47.399999999999864|\n",
            "|2024-02-18|     57.800000000000296|\n",
            "|2024-02-19|      79.49999999999977|\n",
            "|2024-02-20|                   84.0|\n",
            "|2024-02-21|      83.00000000000023|\n",
            "|2024-02-22|                   76.5|\n",
            "|2024-02-23|      84.40000000000032|\n",
            "|2024-02-24|     63.549999999999955|\n",
            "|2024-02-25|      99.77999999999952|\n",
            "|2024-02-26|      92.47000000000025|\n",
            "|2024-02-27|      92.92000000000007|\n",
            "+----------+-----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}