{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiagopecurto/tiagopecurto/blob/main/docs/labs/projs/spbp2425_tp1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgFZlT_g8O1Y"
      },
      "source": [
        "# Sistemas para Processamento de Big Data\n",
        "## TP1 - Energy Meter Monitoring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The sensor data corresponds to regular readings from 11 residential energy meters. The data covers the month of February 2024.\n",
        "\n",
        "Each data sample has the following schema:\n",
        "\n",
        "timestamp | sensor_id | energy\n",
        "----------|-------------|-----------\n",
        "timestamp | string  | float\n",
        "\n",
        "Each energy value (KWh) corresponds to the accumulated value of the meter at the time of measurement. As such,\n",
        "each meter is expected to produce a monotonically increasing series of pairs of timestamp and energy consummed up to that moment.\n",
        "\n",
        "The meters do not start at zero or at the same value.\n"
      ],
      "metadata": {
        "id": "IRDJq9dL0GWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions\n",
        "\n",
        "The following questions should be answered for the month of February and only for this month.\n",
        "\n",
        "### For the group of sensors:\n",
        "\n",
        "1. Compute the total energy consumed.\n",
        "\n",
        "2. Compute the running total energy consumed so far for each day, inclusive.\n",
        "\n",
        "Note: You can approximate the result but using the last reading of each day from each sensor.\n",
        "\n",
        "### For each sensor, separately:\n",
        "\n",
        "3. Compute the total energy consumed and the average energy consumption per day.\n",
        "\n",
        "4. Compute the day of the month with minimum and maximum energy consumption.\n",
        "\n",
        "Note: You can approximate the result but using the last reading of each day from each sensor.\n",
        "\n",
        "### For each sensor, separately, with estimations:\n",
        "\n",
        "**Assumptions:**\n",
        "\n",
        "+ Readings may be missing for extended periods due to communication problems with the sensors.\n",
        "\n",
        "+ Readings are collected do not fall precisely \"on the hour\". The are collected and recorded any time.\n",
        "\n",
        "+ For more precise results, estimate the value of the meter at precise timestamp, using linear interpolation from nearest readings.\n",
        "\n",
        "5. Compute the **estimated** value of each sensor meter for every hour and day of the month (in ascending order).\n",
        "\n",
        "6. Compute the **estimated** running total of the energy consumed so far. The value should be updated every hour."
      ],
      "metadata": {
        "id": "HC6tMDOU7Fdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requeriments\n",
        "\n",
        "Solve each question using Structured Spark, either Dataframes or SQL or both."
      ],
      "metadata": {
        "id": "kdTj-7SD-67o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Grading Criteria\n",
        "\n",
        "+ Grading will also take into account the general clarity of the programming and of the presentation report (notebook).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qN2ogthr_EIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deadline\n",
        "+ November 10, 23h59\n",
        "\n",
        "For each day late, ***0.5 / day penalty***. Penalty accumulates until the grade of the assignment reaches 8.0."
      ],
      "metadata": {
        "id": "8M6lYfT_BpAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Colab Setup\n"
      ],
      "metadata": {
        "id": "81dR9BTgBg1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install PySpark\n",
        "!pip install pyspark findspark --quiet"
      ],
      "metadata": {
        "id": "L2O_3I3x1dbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619bf040-719b-4a0e-ed60-b925f43925e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the dataset\n",
        "\n",
        "!wget -q -O energy-readings.csv https://raw.githubusercontent.com/smduarte/spbd-2425/refs/heads/main/docs/labs/projs/energy-readings.csv\n",
        "!head -2 energy-readings.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB8R09NjYJUW",
        "outputId": "c57945f7-68b5-4b5f-cf18-04395055af68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date;sensor;energy\n",
            "2024-02-01 00:00:00;D;2615.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]') \\\n",
        "\t\t\t\t\t\t.appName('energy').getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "try :\n",
        "    readings = spark.read.csv('energy-readings.csv',\n",
        "                             sep =';', header=True, inferSchema=True)\n",
        "\n",
        "    readings.printSchema()\n",
        "\n",
        "    #0.Filtra os dados para manter apenas o mês de fevereiro de 2024\n",
        "    readings_february = readings.filter((month(\"date\") == 2) & (year(\"date\") == 2024))\n",
        "      #readings_february.show()\n",
        "\n",
        "    #1.Total energy consumed in February\n",
        "    total_energy_consumed = readings_february.groupBy(\"sensor\") \\\n",
        "      .agg((max(\"energy\")-min(\"energy\")).alias(\"energy_consumed_per_sensor\")) \\\n",
        "      .agg(sum(\"energy_consumed_per_sensor\").alias(\"total_energy_consumed\"))\n",
        "      #total_energy_consumed.show()\n",
        "\n",
        "    #2.Total energy consumed by day in February\n",
        "    #2.1: Calcula o consumo diário de cada sensor\n",
        "    daily_consumption_per_sensor = readings_february.withColumn(\"day\", to_date(\"date\")) \\\n",
        "      .groupBy(\"day\", \"sensor\") \\\n",
        "      .agg(round((max(\"energy\") - min(\"energy\"))).alias(\"daily_consumption\")) \\\n",
        "      .orderBy(\"day\", \"sensor\")\n",
        "    daily_consumption_per_sensor.show()\n",
        "\n",
        "    #2.2: Soma o consumo diário para todos os sensores por dia\n",
        "    total_daily_consumption = daily_consumption_per_sensor.groupBy(\"day\") \\\n",
        "      .agg(sum(\"daily_consumption\").alias(\"total_daily_consumption\")) \\\n",
        "      .orderBy(\"day\")\n",
        "    #total_daily_consumption.show()\n",
        "\n",
        "    #3.Compute the total energy consumed and the average energy consumption per day\n",
        "        #Note: utilizou-se a variável de 2.1\n",
        "        #Note2: a função avg() apenas faz a média com o dias em que houve consumos. é necessário dividir pelos 29 dias\n",
        "    total_and_average_consumption = daily_consumption_per_sensor.groupBy(\"sensor\") \\\n",
        "      .agg(round(sum(\"daily_consumption\")).alias(\"total_energy_consumed\"),\n",
        "         (round(sum(\"daily_consumption\")/lit(29))).alias(\"average_daily_consumption\"))\\\n",
        "      .orderBy(\"sensor\")\n",
        "    #total_and_average_consumption.show()\n",
        "\n",
        "    #4.Compute the day of the month with minimum and maximum energy consumption\n",
        "    min_consumption_day = daily_consumption_per_sensor.groupBy(\"sensor\") \\\n",
        "    .agg(min(\"daily_consumption\").alias(\"min_daily_consumption\"))\n",
        "    min_consumption_day.show()\n",
        "    \"\"\"\n",
        "    min_day = daily_consumption_per_sensor.join(min_consumption_day(daily_consumption_per_sensor[\"sensor\"] == min_consumption_day[\"sensor\"]) &\n",
        "    (daily_consumption_per_sensor[\"daily_consumption\"] == min_consumption_day[\"min_daily_consumption\"]),\"inner\") \\\n",
        "    .select(daily_consumption_per_sensor[\"sensor\"], col(\"day\").alias(\"min_consumption_day\"))\n",
        "     \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    #readings.show(5)\n",
        "except Exception as err:\n",
        "    print(err)"
      ],
      "metadata": {
        "id": "zo41adHJYGs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1** - For the group of sensors compute the total energy consumed"
      ],
      "metadata": {
        "id": "lC2GkrPT-UqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]') \\\n",
        "\t\t\t\t\t\t.appName('energy').getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "try :\n",
        "    readings = spark.read.csv('energy-readings.csv',\n",
        "                             sep =';', header=True, inferSchema=True)\n",
        "\n",
        "    #0.Filtra os dados para manter apenas o mês de fevereiro de 2024\n",
        "    readings_february = readings.filter((month(\"date\") == 2) & (year(\"date\") == 2024))\n",
        "      #readings_february.show()\n",
        "\n",
        "    #1.Total energy consumed in February\n",
        "    total_energy_consumed = readings_february.groupBy(\"sensor\") \\\n",
        "      .agg((max(\"energy\")-min(\"energy\")).alias(\"energy_consumed_per_sensor\")) \\\n",
        "      .agg(round(sum(\"energy_consumed_per_sensor\"),3).alias(\"Total Energy Consumed\"))\n",
        "\n",
        "    total_energy_consumed.show()\n",
        "\n",
        "except Exception as err:\n",
        "    print(err)"
      ],
      "metadata": {
        "id": "6mkQZ8uz7etV",
        "outputId": "566483bb-a2f1-49fa-ff9d-03bee8540bc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+\n",
            "|Total Energy Consumed|\n",
            "+---------------------+\n",
            "|              3106.81|\n",
            "+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2** - For the group of sensors, compute the running total energy consumed so far for each day, inclusive"
      ],
      "metadata": {
        "id": "1XA0x4ze_iPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try :\n",
        "  #2.Total energy consumed by day in February\n",
        "  #2.1: Calcula o consumo diário de cada sensor\n",
        "  daily_consumption_per_sensor = readings_february.withColumn(\"day\", to_date(\"date\")) \\\n",
        "    .groupBy(\"day\", \"sensor\") \\\n",
        "    .agg(round(max(\"energy\") - min(\"energy\"),3).alias(\"daily_consumption\")) \\\n",
        "    .orderBy(\"day\", \"sensor\")\n",
        "  #daily_consumption_per_sensor.show()\n",
        "\n",
        "  #2.2: Soma o consumo diário para todos os sensores por dia\n",
        "  total_daily_consumption = daily_consumption_per_sensor.groupBy(\"day\") \\\n",
        "    .agg(round(sum(\"daily_consumption\"),3).alias(\"total_daily_consumption\")) \\\n",
        "    .orderBy(\"day\")\n",
        "  total_daily_consumption.show()\n",
        "\n",
        "except Exception as err:\n",
        "  print(err)"
      ],
      "metadata": {
        "id": "t8_VnTCZ_hgm",
        "outputId": "a62516e1-0ba2-41dc-d7b6-db239dd26add",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------------+\n",
            "|       day|total_daily_consumption|\n",
            "+----------+-----------------------+\n",
            "|2024-02-01|                  119.7|\n",
            "|2024-02-02|                   69.6|\n",
            "|2024-02-09|                   55.7|\n",
            "|2024-02-10|                  113.9|\n",
            "|2024-02-11|                  117.7|\n",
            "|2024-02-12|                  110.5|\n",
            "|2024-02-13|                  112.5|\n",
            "|2024-02-14|                   92.9|\n",
            "|2024-02-15|                   81.0|\n",
            "|2024-02-16|                   47.4|\n",
            "|2024-02-18|                   57.8|\n",
            "|2024-02-19|                   79.5|\n",
            "|2024-02-20|                   84.0|\n",
            "|2024-02-21|                   83.0|\n",
            "|2024-02-22|                   76.5|\n",
            "|2024-02-23|                   84.4|\n",
            "|2024-02-24|                  63.55|\n",
            "|2024-02-25|                  99.78|\n",
            "|2024-02-26|                  92.47|\n",
            "|2024-02-27|                  92.92|\n",
            "+----------+-----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3** - For each sensor separately, compute the total energy consumed and the average energy consumption per day."
      ],
      "metadata": {
        "id": "LwzXwW4fAe5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3.Compute the total energy consumed and the average energy consumption per day\n",
        "        #Note: utilizou-se a variável de 2.1\n",
        "        #Note2: a função avg() apenas faz a média com o dias em que houve consumos. é necessário dividir pelos 29 dias\n",
        "try :\n",
        "  total_and_average_consumption = daily_consumption_per_sensor.groupBy(\"sensor\") \\\n",
        "        .agg(round(sum(\"daily_consumption\"),3).alias(\"total_energy_consumed\"),\n",
        "          (round(sum(\"daily_consumption\")/lit(29),3)).alias(\"average_daily_consumption\"))\\\n",
        "        .orderBy(\"sensor\")\n",
        "\n",
        "  total_and_average_consumption.show()\n",
        "\n",
        "except Exception as err:\n",
        "  print(err)"
      ],
      "metadata": {
        "id": "6wBqWg9cgVE7",
        "outputId": "88d39580-a506-4f4c-c44d-bfda7d4a9c79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------------------+-------------------------+\n",
            "|sensor|total_energy_consumed|average_daily_consumption|\n",
            "+------+---------------------+-------------------------+\n",
            "|     A|               113.18|                    3.903|\n",
            "|     B|                73.51|                    2.535|\n",
            "|     C|               175.21|                    6.042|\n",
            "|     D|                341.7|                   11.783|\n",
            "|     E|               286.59|                    9.882|\n",
            "|     F|                 97.1|                    3.348|\n",
            "|     G|               105.87|                    3.651|\n",
            "|     H|               290.88|                    10.03|\n",
            "|     I|                206.7|                    7.128|\n",
            "|     J|               141.81|                     4.89|\n",
            "|     K|               148.05|                    5.105|\n",
            "+------+---------------------+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4** - For each sensor separately, compute the day of the month with minimum and maximum energy consumption."
      ],
      "metadata": {
        "id": "VKU6Z3tgBxpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4.1 Calcula o valor mínimo e máximo de consumo diário para cada sensor\n",
        "min_consumption_day = daily_consumption_per_sensor.groupBy(\"sensor\") \\\n",
        "    .agg(min(\"daily_consumption\").alias(\"min_daily_consumption\"))\n",
        "\n",
        "max_consumption_day = daily_consumption_per_sensor.groupBy(\"sensor\") \\\n",
        "    .agg(max(\"daily_consumption\").alias(\"max_daily_consumption\"))\n",
        "\n",
        "# 4.3 Filtra para encontrar o dia onde o consumo foi mínimo\n",
        "# Adiciona aliases para resolver a ambiguidade\n",
        "min_day = daily_consumption_per_sensor.alias(\"dcps\").join(\n",
        "    min_consumption_day.alias(\"min_day\"),\n",
        "    (col(\"dcps.sensor\") == col(\"min_day.sensor\")) &\n",
        "    (col(\"dcps.daily_consumption\") == col(\"min_day.min_daily_consumption\")),\"inner\"\n",
        ").select(\n",
        "    col(\"dcps.sensor\"),\n",
        "    col(\"dcps.day\").alias(\"min_consumption_day\"),\n",
        "    col(\"dcps.daily_consumption\").alias(\"min_daily_consumption\")\n",
        ").orderBy(\"sensor\")\n",
        "\n",
        "# 4.4 Filtra para encontrar o dia onde o consumo foi máximo\n",
        "max_day = daily_consumption_per_sensor.alias(\"dcps\").join(\n",
        "    max_consumption_day.alias(\"max_day\"),\n",
        "    (col(\"dcps.sensor\") == col(\"max_day.sensor\")) &\n",
        "    (col(\"dcps.daily_consumption\") == col(\"max_day.max_daily_consumption\")),\"inner\"\n",
        ").select(\n",
        "    col(\"dcps.sensor\"),\n",
        "    col(\"dcps.day\").alias(\"max_consumption_day\"),\n",
        "    col(\"dcps.daily_consumption\").alias(\"max_daily_consumption\")\n",
        ").orderBy(\"sensor\")\n",
        "\n",
        "\n",
        "\n",
        "# 4.5 Exibe os resultados\n",
        "min_day.show()\n",
        "max_day.show()"
      ],
      "metadata": {
        "id": "jCwo_JnZB_Du",
        "outputId": "dc83a84a-1e36-4fbd-da80-5592e913cd96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+---------------------+\n",
            "|sensor|min_consumption_day|min_daily_consumption|\n",
            "+------+-------------------+---------------------+\n",
            "|     A|         2024-02-24|                 0.77|\n",
            "|     B|         2024-02-09|                  0.1|\n",
            "|     C|         2024-02-02|                  1.6|\n",
            "|     C|         2024-02-23|                  1.6|\n",
            "|     D|         2024-02-16|                  5.7|\n",
            "|     E|         2024-02-23|                  4.7|\n",
            "|     F|         2024-02-18|                  0.8|\n",
            "|     G|         2024-02-09|                  0.7|\n",
            "|     H|         2024-02-26|                  2.1|\n",
            "|     I|         2024-02-18|                  0.5|\n",
            "|     J|         2024-02-18|                  1.7|\n",
            "|     K|         2024-02-16|                  1.2|\n",
            "+------+-------------------+---------------------+\n",
            "\n",
            "+------+-------------------+---------------------+\n",
            "|sensor|max_consumption_day|max_daily_consumption|\n",
            "+------+-------------------+---------------------+\n",
            "|     A|         2024-02-01|                  8.1|\n",
            "|     B|         2024-02-12|                  9.9|\n",
            "|     C|         2024-02-11|                 14.0|\n",
            "|     D|         2024-02-29|                 26.4|\n",
            "|     E|         2024-02-13|                 20.6|\n",
            "|     F|         2024-02-29|                12.87|\n",
            "|     G|         2024-02-10|                  9.3|\n",
            "|     H|         2024-02-28|                26.11|\n",
            "|     I|         2024-02-29|                20.66|\n",
            "|     J|         2024-02-11|                 10.0|\n",
            "|     K|         2024-02-11|                 10.2|\n",
            "+------+-------------------+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A5pre2dzMW6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Window\n",
        "from pyspark.sql.functions import col, lag, lead, to_date, unix_timestamp, expr, sequence, explode, lit\n",
        "from pyspark.sql.types import DateType\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Passo 1: Extrair o valor máximo ou mínimo diário para cada sensor\n",
        "daily_extreme = readings_february.withColumn(\"day\", to_date(\"date\")) \\\n",
        "    .groupBy(\"sensor\", \"day\") \\\n",
        "    .agg(max(\"energy\").alias(\"daily_extreme_energy\")) \\\n",
        "    .orderBy(\"sensor\", \"day\")\n",
        "\n",
        "# Passo 2: Gerar um DataFrame com todas as datas de fevereiro para cada sensor usando datetime\n",
        "start_date = datetime(2024, 2, 1)\n",
        "end_date = datetime(2024, 2, 29)\n",
        "all_days = [(start_date + timedelta(days=i)).date() for i in range((end_date - start_date).days + 1)]\n",
        "\n",
        "# Cria um DataFrame com todas as datas para fevereiro\n",
        "all_days_df = spark.createDataFrame([(d,) for d in all_days], [\"day\"])\n",
        "\n",
        "# Obter os sensores distintos\n",
        "sensors_df = readings_february.select(\"sensor\").distinct()\n",
        "\n",
        "# Realizar um cross join entre os sensores e todas as datas para obter todas as combinações\n",
        "all_days_per_sensor = sensors_df.crossJoin(all_days_df)\n",
        "\n",
        "# Passo 3: Fazer um left join para garantir que todos os dias aparecem para cada sensor\n",
        "full_daily_data = all_days_per_sensor.join(daily_extreme, [\"sensor\", \"day\"], \"left\") \\\n",
        "    .orderBy(\"sensor\", \"day\")\n",
        "\n",
        "# Passo 4: Definir a janela e aplicar a interpolação linear entre o último e o próximo valor conhecido para blocos\n",
        "window_spec = Window.partitionBy(\"sensor\").orderBy(\"day\")\n",
        "\n",
        "# Adicionar colunas com as leituras anteriores e seguintes para interpolação\n",
        "# Interpolação linear para preencher blocos de dias consecutivos NULL\n",
        "interpolated_data = full_daily_data \\\n",
        "    .withColumn(\"prev_day\", lag(\"day\").over(window_spec)) \\\n",
        "    .withColumn(\"next_day\", lead(\"day\").over(window_spec)) \\\n",
        "    .withColumn(\"prev_energy\", lag(\"daily_extreme_energy\").over(window_spec)) \\\n",
        "    .withColumn(\"next_energy\", lead(\"daily_extreme_energy\").over(window_spec)) \\\n",
        "    .withColumn(\"interpolated_energy\", expr(\"\"\"\n",
        "        CASE\n",
        "            WHEN daily_extreme_energy IS NOT NULL THEN daily_extreme_energy\n",
        "            WHEN prev_energy IS NOT NULL AND next_energy IS NOT NULL THEN\n",
        "                prev_energy + (unix_timestamp(day) - unix_timestamp(prev_day)) /\n",
        "                (unix_timestamp(next_day) - unix_timestamp(prev_day)) *\n",
        "                (next_energy - prev_energy)\n",
        "            ELSE NULL\n",
        "        END\n",
        "    \"\"\"))\n",
        "\n",
        "# Selecionar o resultado final com o valor interpolado para blocos\n",
        "result = interpolated_data.select(\"sensor\", \"day\", \"daily_extreme_energy\", \"interpolated_energy\") \\\n",
        "    .orderBy(\"sensor\", \"day\")\n",
        "\n",
        "# Exibir os resultados interpolados\n",
        "result.show(50)"
      ],
      "metadata": {
        "id": "7m9glBHGYs8p",
        "outputId": "a089e099-2d0c-4a7d-9f80-51806208510f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+--------------------+-------------------+\n",
            "|sensor|       day|daily_extreme_energy|interpolated_energy|\n",
            "+------+----------+--------------------+-------------------+\n",
            "|     A|2024-02-01|               658.6|              658.6|\n",
            "|     A|2024-02-02|               663.4|              663.4|\n",
            "|     A|2024-02-03|                NULL|               NULL|\n",
            "|     A|2024-02-04|                NULL|               NULL|\n",
            "|     A|2024-02-05|                NULL|               NULL|\n",
            "|     A|2024-02-06|                NULL|               NULL|\n",
            "|     A|2024-02-07|                NULL|               NULL|\n",
            "|     A|2024-02-08|                NULL|               NULL|\n",
            "|     A|2024-02-09|               712.5|              712.5|\n",
            "|     A|2024-02-10|               719.9|              719.9|\n",
            "|     A|2024-02-11|               726.3|              726.3|\n",
            "|     A|2024-02-12|               733.0|              733.0|\n",
            "|     A|2024-02-13|               739.8|              739.8|\n",
            "|     A|2024-02-14|               744.8|              744.8|\n",
            "|     A|2024-02-15|               749.1|              749.1|\n",
            "|     A|2024-02-16|               751.0|              751.0|\n",
            "|     A|2024-02-17|                NULL|             757.15|\n",
            "|     A|2024-02-18|               763.3|              763.3|\n",
            "|     A|2024-02-19|               769.0|              769.0|\n",
            "|     A|2024-02-20|               773.3|              773.3|\n",
            "|     A|2024-02-21|               778.2|              778.2|\n",
            "|     A|2024-02-22|               783.3|              783.3|\n",
            "|     A|2024-02-23|               786.3|              786.3|\n",
            "|     A|2024-02-24|              788.17|             788.17|\n",
            "|     A|2024-02-25|              792.06|             792.06|\n",
            "|     A|2024-02-26|              795.64|             795.64|\n",
            "|     A|2024-02-27|              802.44|             802.44|\n",
            "|     A|2024-02-28|              809.52|             809.52|\n",
            "|     A|2024-02-29|              816.88|             816.88|\n",
            "|     B|2024-02-01|               631.7|              631.7|\n",
            "|     B|2024-02-02|               636.3|              636.3|\n",
            "|     B|2024-02-03|                NULL|               NULL|\n",
            "|     B|2024-02-04|                NULL|               NULL|\n",
            "|     B|2024-02-05|                NULL|               NULL|\n",
            "|     B|2024-02-06|                NULL|               NULL|\n",
            "|     B|2024-02-07|                NULL|               NULL|\n",
            "|     B|2024-02-08|                NULL|               NULL|\n",
            "|     B|2024-02-09|               688.7|              688.7|\n",
            "|     B|2024-02-10|               695.4|              695.4|\n",
            "|     B|2024-02-11|               701.2|              701.2|\n",
            "|     B|2024-02-12|               711.1|              711.1|\n",
            "|     B|2024-02-13|               718.2|              718.2|\n",
            "|     B|2024-02-14|               726.3|              726.3|\n",
            "|     B|2024-02-15|               732.6|              732.6|\n",
            "|     B|2024-02-16|               738.6|              738.6|\n",
            "|     B|2024-02-17|                NULL|             740.35|\n",
            "|     B|2024-02-18|               742.1|              742.1|\n",
            "|     B|2024-02-19|               743.4|              743.4|\n",
            "|     B|2024-02-20|               744.8|              744.8|\n",
            "|     B|2024-02-21|               746.1|              746.1|\n",
            "+------+----------+--------------------+-------------------+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cDJQQnjgbMZ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}