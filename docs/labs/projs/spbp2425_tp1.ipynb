{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiagopecurto/tiagopecurto/blob/main/docs/labs/projs/spbp2425_tp1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgFZlT_g8O1Y"
      },
      "source": [
        "# Sistemas para Processamento de Big Data\n",
        "## TP1 - Energy Meter Monitoring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The sensor data corresponds to regular readings from 11 residential energy meters. The data covers the month of February 2024.\n",
        "\n",
        "Each data sample has the following schema:\n",
        "\n",
        "timestamp | sensor_id | energy\n",
        "----------|-------------|-----------\n",
        "timestamp | string  | float\n",
        "\n",
        "Each energy value (KWh) corresponds to the accumulated value of the meter at the time of measurement. As such,\n",
        "each meter is expected to produce a monotonically increasing series of pairs of timestamp and energy consummed up to that moment.\n",
        "\n",
        "The meters do not start at zero or at the same value.\n"
      ],
      "metadata": {
        "id": "IRDJq9dL0GWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions\n",
        "\n",
        "The following questions should be answered for the month of February and only for this month.\n",
        "\n",
        "### For the group of sensors:\n",
        "\n",
        "1. Compute the total energy consumed.\n",
        "\n",
        "2. Compute the running total energy consumed so far for each day, inclusive.\n",
        "\n",
        "Note: You can approximate the result but using the last reading of each day from each sensor.\n",
        "\n",
        "### For each sensor, separately:\n",
        "\n",
        "3. Compute the total energy consumed and the average energy consumption per day.\n",
        "\n",
        "4. Compute the day of the month with minimum and maximum energy consumption.\n",
        "\n",
        "Note: You can approximate the result but using the last reading of each day from each sensor.\n",
        "\n",
        "### For each sensor, separately, with estimations:\n",
        "\n",
        "**Assumptions:**\n",
        "\n",
        "+ Readings may be missing for extended periods due to communication problems with the sensors.\n",
        "\n",
        "+ Readings are collected do not fall precisely \"on the hour\". The are collected and recorded any time.\n",
        "\n",
        "+ For more precise results, estimate the value of the meter at precise timestamp, using linear interpolation from nearest readings.\n",
        "\n",
        "5. Compute the **estimated** value of each sensor meter for every hour and day of the month (in ascending order).\n",
        "\n",
        "6. Compute the **estimated** running total of the energy consumed so far. The value should be updated every hour."
      ],
      "metadata": {
        "id": "HC6tMDOU7Fdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requeriments\n",
        "\n",
        "Solve each question using Structured Spark, either Dataframes or SQL or both."
      ],
      "metadata": {
        "id": "kdTj-7SD-67o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Grading Criteria\n",
        "\n",
        "+ Grading will also take into account the general clarity of the programming and of the presentation report (notebook).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qN2ogthr_EIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deadline\n",
        "+ November 10, 23h59\n",
        "\n",
        "For each day late, ***0.5 / day penalty***. Penalty accumulates until the grade of the assignment reaches 8.0."
      ],
      "metadata": {
        "id": "8M6lYfT_BpAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Colab Setup\n"
      ],
      "metadata": {
        "id": "81dR9BTgBg1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install PySpark\n",
        "!pip install pyspark findspark --quiet"
      ],
      "metadata": {
        "id": "L2O_3I3x1dbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619bf040-719b-4a0e-ed60-b925f43925e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the dataset\n",
        "\n",
        "!wget -q -O energy-readings.csv https://raw.githubusercontent.com/smduarte/spbd-2425/refs/heads/main/docs/labs/projs/energy-readings.csv\n",
        "!head -2 energy-readings.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB8R09NjYJUW",
        "outputId": "bfbf1d11-56b8-4363-ff35-c24150e6ba9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date;sensor;energy\n",
            "2024-02-01 00:00:00;D;2615.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]') \\\n",
        "\t\t\t\t\t\t.appName('energy').getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "try :\n",
        "    readings = spark.read.csv('energy-readings.csv',\n",
        "                             sep =';', header=True, inferSchema=True)\n",
        "\n",
        "    readings.printSchema()\n",
        "\n",
        "    #0.Filtra os dados para manter apenas o mês de fevereiro de 2024\n",
        "    readings_february = readings.filter((month(\"date\") == 2) & (year(\"date\") == 2024))\n",
        "      #readings_february.show()\n",
        "\n",
        "    #1.Total energy consumed in February\n",
        "    total_energy_consumed = readings_february.groupBy(\"sensor\") \\\n",
        "      .agg((max(\"energy\")-min(\"energy\")).alias(\"energy_consumed_per_sensor\")) \\\n",
        "      .agg(sum(\"energy_consumed_per_sensor\").alias(\"total_energy_consumed\"))\n",
        "      #total_energy_consumed.show()\n",
        "\n",
        "    #2.Total energy consumed by day in February\n",
        "    #2.1: Calcula o consumo diário de cada sensor\n",
        "    daily_consumption_per_sensor = readings_february.withColumn(\"day\", to_date(\"date\")) \\\n",
        "      .groupBy(\"day\", \"sensor\") \\\n",
        "      .agg(round((max(\"energy\") - min(\"energy\"))).alias(\"daily_consumption\")) \\\n",
        "      .orderBy(\"day\", \"sensor\")\n",
        "    daily_consumption_per_sensor.show()\n",
        "\n",
        "    #2.2: Soma o consumo diário para todos os sensores por dia\n",
        "    total_daily_consumption = daily_consumption_per_sensor.groupBy(\"day\") \\\n",
        "      .agg(sum(\"daily_consumption\").alias(\"total_daily_consumption\")) \\\n",
        "      .orderBy(\"day\")\n",
        "    #total_daily_consumption.show()\n",
        "\n",
        "    #3.Compute the total energy consumed and the average energy consumption per day\n",
        "        #Note: utilizou-se a variável de 2.1\n",
        "        #Note2: a função avg() apenas faz a média com o dias em que houve consumos. é necessário dividir pelos 29 dias\n",
        "    total_and_average_consumption = daily_consumption_per_sensor.groupBy(\"sensor\") \\\n",
        "      .agg(round(sum(\"daily_consumption\")).alias(\"total_energy_consumed\"),\n",
        "         (round(sum(\"daily_consumption\")/lit(29))).alias(\"average_daily_consumption\"))\\\n",
        "      .orderBy(\"sensor\")\n",
        "    #total_and_average_consumption.show()\n",
        "\n",
        "    #4.Compute the day of the month with minimum and maximum energy consumption\n",
        "    min_consumption_day = daily_consumption_per_sensor.groupBy(\"sensor\") \\\n",
        "    .agg(min(\"daily_consumption\").alias(\"min_daily_consumption\"))\n",
        "    min_consumption_day.show()\n",
        "    \"\"\"\n",
        "    min_day = daily_consumption_per_sensor.join(min_consumption_day(daily_consumption_per_sensor[\"sensor\"] == min_consumption_day[\"sensor\"]) &\n",
        "    (daily_consumption_per_sensor[\"daily_consumption\"] == min_consumption_day[\"min_daily_consumption\"]),\"inner\") \\\n",
        "    .select(daily_consumption_per_sensor[\"sensor\"], col(\"day\").alias(\"min_consumption_day\"))\n",
        "     \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    #readings.show(5)\n",
        "except Exception as err:\n",
        "    print(err)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo41adHJYGs6",
        "outputId": "4a8507fd-ae20-426e-8125-c50842b8c0f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- date: timestamp (nullable = true)\n",
            " |-- sensor: string (nullable = true)\n",
            " |-- energy: double (nullable = true)\n",
            "\n",
            "+----------+------+-----------------+\n",
            "|       day|sensor|daily_consumption|\n",
            "+----------+------+-----------------+\n",
            "|2024-02-01|     A|              8.0|\n",
            "|2024-02-01|     B|              4.0|\n",
            "|2024-02-01|     C|             10.0|\n",
            "|2024-02-01|     D|             13.0|\n",
            "|2024-02-01|     E|             16.0|\n",
            "|2024-02-01|     F|             11.0|\n",
            "|2024-02-01|     G|              3.0|\n",
            "|2024-02-01|     H|             24.0|\n",
            "|2024-02-01|     I|             20.0|\n",
            "|2024-02-01|     J|              3.0|\n",
            "|2024-02-01|     K|              8.0|\n",
            "|2024-02-02|     A|              5.0|\n",
            "|2024-02-02|     B|              5.0|\n",
            "|2024-02-02|     C|              2.0|\n",
            "|2024-02-02|     D|              6.0|\n",
            "|2024-02-02|     E|             10.0|\n",
            "|2024-02-02|     F|              7.0|\n",
            "|2024-02-02|     G|              4.0|\n",
            "|2024-02-02|     H|              6.0|\n",
            "|2024-02-02|     I|             13.0|\n",
            "+----------+------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+---------------------+\n",
            "|sensor|min_daily_consumption|\n",
            "+------+---------------------+\n",
            "|     K|                  1.0|\n",
            "|     F|                  1.0|\n",
            "|     E|                  5.0|\n",
            "|     B|                  0.0|\n",
            "|     D|                  6.0|\n",
            "|     C|                  2.0|\n",
            "|     J|                  2.0|\n",
            "|     A|                  1.0|\n",
            "|     G|                  1.0|\n",
            "|     I|                  1.0|\n",
            "|     H|                  2.0|\n",
            "+------+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1** - For the group of sensors compute the total energy consumed"
      ],
      "metadata": {
        "id": "lC2GkrPT-UqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]') \\\n",
        "\t\t\t\t\t\t.appName('energy').getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "try :\n",
        "    readings = spark.read.csv('energy-readings.csv',\n",
        "                             sep =';', header=True, inferSchema=True)\n",
        "\n",
        "    #0.Filtra os dados para manter apenas o mês de fevereiro de 2024\n",
        "    readings_february = readings.filter((month(\"date\") == 2) & (year(\"date\") == 2024))\n",
        "      #readings_february.show()\n",
        "\n",
        "    #1.Total energy consumed in February\n",
        "    total_energy_consumed = readings_february.groupBy(\"sensor\") \\\n",
        "      .agg((max(\"energy\")-min(\"energy\")).alias(\"energy_consumed_per_sensor\")) \\\n",
        "      .agg(round(sum(\"energy_consumed_per_sensor\"),3).alias(\"Total Energy Consumed\"))\n",
        "\n",
        "    total_energy_consumed.show()\n",
        "\n",
        "except Exception as err:\n",
        "    print(err)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mkQZ8uz7etV",
        "outputId": "b0f0978b-5985-4cf1-bd90-826f77c4102a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+\n",
            "|Total Energy Consumed|\n",
            "+---------------------+\n",
            "|              3106.81|\n",
            "+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2** - For the group of sensors, compute the running total energy consumed so far for each day, inclusive"
      ],
      "metadata": {
        "id": "1XA0x4ze_iPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try :\n",
        "  #2.Total energy consumed by day in February\n",
        "  #2.1: Calcula o consumo diário de cada sensor\n",
        "  daily_consumption_per_sensor = readings_february.withColumn(\"day\", to_date(\"date\")) \\\n",
        "    .groupBy(\"day\", \"sensor\") \\\n",
        "    .agg(round(max(\"energy\") - min(\"energy\"),3).alias(\"daily_consumption\")) \\\n",
        "    .orderBy(\"day\", \"sensor\")\n",
        "  #daily_consumption_per_sensor.show()\n",
        "\n",
        "  #2.2: Soma o consumo diário para todos os sensores por dia\n",
        "  total_daily_consumption = daily_consumption_per_sensor.groupBy(\"day\") \\\n",
        "    .agg(round(sum(\"daily_consumption\"),3).alias(\"total_daily_consumption\")) \\\n",
        "    .orderBy(\"day\")\n",
        "  total_daily_consumption.show()\n",
        "\n",
        "except Exception as err:\n",
        "  print(err)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8_VnTCZ_hgm",
        "outputId": "b3cae195-9ef3-4ac0-c4ff-2371505c0145"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------------+\n",
            "|       day|total_daily_consumption|\n",
            "+----------+-----------------------+\n",
            "|2024-02-01|                  119.7|\n",
            "|2024-02-02|                   69.6|\n",
            "|2024-02-09|                   55.7|\n",
            "|2024-02-10|                  113.9|\n",
            "|2024-02-11|                  117.7|\n",
            "|2024-02-12|                  110.5|\n",
            "|2024-02-13|                  112.5|\n",
            "|2024-02-14|                   92.9|\n",
            "|2024-02-15|                   81.0|\n",
            "|2024-02-16|                   47.4|\n",
            "|2024-02-18|                   57.8|\n",
            "|2024-02-19|                   79.5|\n",
            "|2024-02-20|                   84.0|\n",
            "|2024-02-21|                   83.0|\n",
            "|2024-02-22|                   76.5|\n",
            "|2024-02-23|                   84.4|\n",
            "|2024-02-24|                  63.55|\n",
            "|2024-02-25|                  99.78|\n",
            "|2024-02-26|                  92.47|\n",
            "|2024-02-27|                  92.92|\n",
            "+----------+-----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3** - For each sensor separately, compute the total energy consumed and the average energy consumption per day."
      ],
      "metadata": {
        "id": "LwzXwW4fAe5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3.Compute the total energy consumed and the average energy consumption per day\n",
        "        #Note: utilizou-se a variável de 2.1\n",
        "        #Note2: a função avg() apenas faz a média com o dias em que houve consumos. é necessário dividir pelos 29 dias\n",
        "try :\n",
        "  total_and_average_consumption = daily_consumption_per_sensor.groupBy(\"sensor\") \\\n",
        "        .agg(round(sum(\"daily_consumption\"),3).alias(\"total_energy_consumed\"),\n",
        "          (round(sum(\"daily_consumption\")/lit(29),3)).alias(\"average_daily_consumption\"))\\\n",
        "        .orderBy(\"sensor\")\n",
        "\n",
        "  total_and_average_consumption.show()\n",
        "\n",
        "except Exception as err:\n",
        "  print(err)"
      ],
      "metadata": {
        "id": "6wBqWg9cgVE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb529986-2251-4083-f66b-06eebc49e780"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------------------+-------------------------+\n",
            "|sensor|total_energy_consumed|average_daily_consumption|\n",
            "+------+---------------------+-------------------------+\n",
            "|     A|               113.18|                    3.903|\n",
            "|     B|                73.51|                    2.535|\n",
            "|     C|               175.21|                    6.042|\n",
            "|     D|                341.7|                   11.783|\n",
            "|     E|               286.59|                    9.882|\n",
            "|     F|                 97.1|                    3.348|\n",
            "|     G|               105.87|                    3.651|\n",
            "|     H|               290.88|                    10.03|\n",
            "|     I|                206.7|                    7.128|\n",
            "|     J|               141.81|                     4.89|\n",
            "|     K|               148.05|                    5.105|\n",
            "+------+---------------------+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4** - For each sensor separately, compute the day of the month with minimum and maximum energy consumption."
      ],
      "metadata": {
        "id": "VKU6Z3tgBxpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1 Calcula o valor mínimo e máximo de consumo diário para cada sensor\n",
        "min_consumption_day = daily_consumption_per_sensor.groupBy(\"sensor\") \\\n",
        "    .agg(min(\"daily_consumption\").alias(\"min_daily_consumption\"))\n",
        "\n",
        "max_consumption_day = daily_consumption_per_sensor.groupBy(\"sensor\") \\\n",
        "    .agg(max(\"daily_consumption\").alias(\"max_daily_consumption\"))\n",
        "\n",
        "max_consumption_day.show()\n",
        "\n",
        "# 4.3 Filtra para encontrar o dia onde o consumo foi mínimo\n",
        "# Adiciona aliases para resolver a ambiguidade\n",
        "min_day = daily_consumption_per_sensor.alias(\"dcps\").join(\n",
        "    min_consumption_day.alias(\"min_day\"),\n",
        "    (col(\"dcps.sensor\") == col(\"min_day.sensor\")) &\n",
        "    (col(\"dcps.daily_consumption\") == col(\"min_day.min_daily_consumption\")),\"inner\"\n",
        ").select(\n",
        "    col(\"dcps.sensor\"),\n",
        "    col(\"dcps.day\").alias(\"min_consumption_day\"),\n",
        "    col(\"dcps.daily_consumption\").alias(\"min_daily_consumption\")\n",
        ").orderBy(\"sensor\")\n",
        "\n",
        "# 4.4 Filtra para encontrar o dia onde o consumo foi máximo\n",
        "max_day = daily_consumption_per_sensor.alias(\"dcps\").join(\n",
        "    max_consumption_day.alias(\"max_day\"),\n",
        "    (col(\"dcps.sensor\") == col(\"max_day.sensor\")) &\n",
        "    (col(\"dcps.daily_consumption\") == col(\"max_day.max_daily_consumption\")),\"inner\"\n",
        ").select(\n",
        "    col(\"dcps.sensor\"),\n",
        "    col(\"dcps.day\").alias(\"max_consumption_day\"),\n",
        "    col(\"dcps.daily_consumption\").alias(\"max_daily_consumption\")\n",
        ").orderBy(\"sensor\")\n",
        "\n",
        "\n",
        "\n",
        "# 4.5 Exibe os resultados\n",
        "min_day.show()\n",
        "max_day.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCwo_JnZB_Du",
        "outputId": "31ea1482-dcf3-4f47-b026-21ee06c454bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------------------+\n",
            "|sensor|max_daily_consumption|\n",
            "+------+---------------------+\n",
            "|     K|                 10.2|\n",
            "|     F|                12.87|\n",
            "|     E|                 20.6|\n",
            "|     B|                  9.9|\n",
            "|     D|                 26.4|\n",
            "|     C|                 14.0|\n",
            "|     J|                 10.0|\n",
            "|     A|                  8.1|\n",
            "|     G|                  9.3|\n",
            "|     I|                20.66|\n",
            "|     H|                26.11|\n",
            "+------+---------------------+\n",
            "\n",
            "+------+-------------------+---------------------+\n",
            "|sensor|min_consumption_day|min_daily_consumption|\n",
            "+------+-------------------+---------------------+\n",
            "|     A|         2024-02-24|                 0.77|\n",
            "|     B|         2024-02-09|                  0.1|\n",
            "|     C|         2024-02-02|                  1.6|\n",
            "|     C|         2024-02-23|                  1.6|\n",
            "|     D|         2024-02-16|                  5.7|\n",
            "|     E|         2024-02-23|                  4.7|\n",
            "|     F|         2024-02-18|                  0.8|\n",
            "|     G|         2024-02-09|                  0.7|\n",
            "|     H|         2024-02-26|                  2.1|\n",
            "|     I|         2024-02-18|                  0.5|\n",
            "|     J|         2024-02-18|                  1.7|\n",
            "|     K|         2024-02-16|                  1.2|\n",
            "+------+-------------------+---------------------+\n",
            "\n",
            "+------+-------------------+---------------------+\n",
            "|sensor|max_consumption_day|max_daily_consumption|\n",
            "+------+-------------------+---------------------+\n",
            "|     A|         2024-02-01|                  8.1|\n",
            "|     B|         2024-02-12|                  9.9|\n",
            "|     C|         2024-02-11|                 14.0|\n",
            "|     D|         2024-02-29|                 26.4|\n",
            "|     E|         2024-02-13|                 20.6|\n",
            "|     F|         2024-02-29|                12.87|\n",
            "|     G|         2024-02-10|                  9.3|\n",
            "|     H|         2024-02-28|                26.11|\n",
            "|     I|         2024-02-29|                20.66|\n",
            "|     J|         2024-02-11|                 10.0|\n",
            "|     K|         2024-02-11|                 10.2|\n",
            "+------+-------------------+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5** - Compute the estimated value of each sensor meter for every hour and day of the month (in ascending order)."
      ],
      "metadata": {
        "id": "A5pre2dzMW6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Função de Interpolação Linear - Retirada de StackOverflow \"Pyspark : Interpolation of missing values in pyspark dataframe observed\"\n",
        "    #Link: https://stackoverflow.com/questions/53077639/pyspark-interpolation-of-missing-values-in-pyspark-dataframe-observed\n",
        "def fill_linear_interpolation(df, id_cols, order_col, value_col):\n",
        "    w = Window.partitionBy(id_cols).orderBy(order_col)\n",
        "    new_df = df.withColumn('rn', F.row_number().over(w))\n",
        "    new_df = new_df.withColumn('rn_not_null', F.when(F.col(value_col).isNotNull(), F.col('rn')))\n",
        "\n",
        "    w_start = Window.partitionBy(id_cols).orderBy(order_col).rowsBetween(Window.unboundedPreceding, -1)\n",
        "    new_df = new_df.withColumn('start_val', F.last(value_col, True).over(w_start))\n",
        "    new_df = new_df.withColumn('start_rn', F.last('rn_not_null', True).over(w_start))\n",
        "\n",
        "    w_end = Window.partitionBy(id_cols).orderBy(order_col).rowsBetween(0, Window.unboundedFollowing)\n",
        "    new_df = new_df.withColumn('end_val', F.first(value_col, True).over(w_end))\n",
        "    new_df = new_df.withColumn('end_rn', F.first('rn_not_null', True).over(w_end))\n",
        "\n",
        "    if not isinstance(id_cols, list):\n",
        "        id_cols = [id_cols]\n",
        "\n",
        "    new_df = new_df.withColumn('diff_rn', F.col('end_rn') - F.col('start_rn'))\n",
        "    new_df = new_df.withColumn('curr_rn', F.col('diff_rn') - (F.col('end_rn') - F.col('rn')))\n",
        "\n",
        "    lin_interp_func = (F.col('start_val') + (F.col('end_val') - F.col('start_val')) / F.col('diff_rn') * F.col('curr_rn'))\n",
        "    new_df = new_df.withColumn(value_col, F.when(F.col(value_col).isNull(), lin_interp_func).otherwise(F.col(value_col)))\n",
        "\n",
        "    return new_df.drop('rn', 'rn_not_null', 'start_val', 'end_val', 'start_rn', 'end_rn', 'diff_rn', 'curr_rn')\n",
        "\n",
        "# 1. Cria uma série de datas para todo o mês de fevereiro de 2024\n",
        "\"\"\"start_date = datetime(2024, 2, 1)\n",
        "end_date = datetime(2024, 2, 29)\n",
        "date_series = [(start_date + timedelta(days=i)).date() for i in range((end_date - start_date).days + 1)]\n",
        "date_df = spark.createDataFrame(date_series, DateType()).toDF(\"day\")\n",
        "\"\"\"\n",
        "\n",
        "date_range_df = spark.createDataFrame([(datetime(2024, 2, 1), datetime(2024, 2, 29))], [\"start_date\", \"end_date\"])\n",
        "date_df = date_range_df.select(explode(sequence(\"start_date\", \"end_date\")).alias(\"day\"))\n",
        "\n",
        "date_df.show()\n",
        "\n",
        "# 2. Obter a leitura máxima diária para cada sensor\n",
        "readings_february = readings_february.withColumn(\"day\", to_date(\"date\"))\n",
        "max_daily_readings = readings_february \\\n",
        "    .groupBy(\"sensor\", \"day\") \\\n",
        "    .agg(max(\"energy\").alias(\"max_energy\")) \\\n",
        "    .orderBy(\"sensor\", \"day\")\n",
        "\n",
        "max_daily_readings.show()\n",
        "\n",
        "# 3. Realizar um join para garantir que todos os dias de fevereiro estão presentes para cada sensor\n",
        "sensors_df = max_daily_readings.select(\"sensor\").distinct()\n",
        "all_dates_for_sensors = sensors_df.crossJoin(date_df)\n",
        "\n",
        "all_dates_for_sensors.show()\n",
        "\n",
        "# Left join para completar com dados reais onde disponíveis e null onde não há contagens\n",
        "complete_daily_data = all_dates_for_sensors.join(\n",
        "    max_daily_readings,\n",
        "    on=[\"sensor\", \"day\"],\n",
        "    how=\"left\"\n",
        ").orderBy(\"sensor\", \"day\")\n",
        "\n",
        "complete_daily_data.show()\n",
        "\n",
        "# 4. Aplicar a função de interpolação linear\n",
        "interpolated_daily_data = fill_linear_interpolation(complete_daily_data, id_cols=\"sensor\", order_col=\"day\", value_col=\"max_energy\")\n",
        "\n",
        "# 5. Exibir o resultado final com os valores interpolados\n",
        "interpolated_daily_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GavR91du468j",
        "outputId": "0668ccaa-4933-40a2-f406-85c1716e8ae4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|                day|\n",
            "+-------------------+\n",
            "|2024-02-01 00:00:00|\n",
            "|2024-02-02 00:00:00|\n",
            "|2024-02-03 00:00:00|\n",
            "|2024-02-04 00:00:00|\n",
            "|2024-02-05 00:00:00|\n",
            "|2024-02-06 00:00:00|\n",
            "|2024-02-07 00:00:00|\n",
            "|2024-02-08 00:00:00|\n",
            "|2024-02-09 00:00:00|\n",
            "|2024-02-10 00:00:00|\n",
            "|2024-02-11 00:00:00|\n",
            "|2024-02-12 00:00:00|\n",
            "|2024-02-13 00:00:00|\n",
            "|2024-02-14 00:00:00|\n",
            "|2024-02-15 00:00:00|\n",
            "|2024-02-16 00:00:00|\n",
            "|2024-02-17 00:00:00|\n",
            "|2024-02-18 00:00:00|\n",
            "|2024-02-19 00:00:00|\n",
            "|2024-02-20 00:00:00|\n",
            "+-------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+----------+----------+\n",
            "|sensor|       day|max_energy|\n",
            "+------+----------+----------+\n",
            "|     A|2024-02-01|     658.6|\n",
            "|     A|2024-02-02|     663.4|\n",
            "|     A|2024-02-09|     712.5|\n",
            "|     A|2024-02-10|     719.9|\n",
            "|     A|2024-02-11|     726.3|\n",
            "|     A|2024-02-12|     733.0|\n",
            "|     A|2024-02-13|     739.8|\n",
            "|     A|2024-02-14|     744.8|\n",
            "|     A|2024-02-15|     749.1|\n",
            "|     A|2024-02-16|     751.0|\n",
            "|     A|2024-02-18|     763.3|\n",
            "|     A|2024-02-19|     769.0|\n",
            "|     A|2024-02-20|     773.3|\n",
            "|     A|2024-02-21|     778.2|\n",
            "|     A|2024-02-22|     783.3|\n",
            "|     A|2024-02-23|     786.3|\n",
            "|     A|2024-02-24|    788.17|\n",
            "|     A|2024-02-25|    792.06|\n",
            "|     A|2024-02-26|    795.64|\n",
            "|     A|2024-02-27|    802.44|\n",
            "+------+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+-------------------+\n",
            "|sensor|                day|\n",
            "+------+-------------------+\n",
            "|     K|2024-02-01 00:00:00|\n",
            "|     F|2024-02-01 00:00:00|\n",
            "|     E|2024-02-01 00:00:00|\n",
            "|     B|2024-02-01 00:00:00|\n",
            "|     D|2024-02-01 00:00:00|\n",
            "|     C|2024-02-01 00:00:00|\n",
            "|     J|2024-02-01 00:00:00|\n",
            "|     A|2024-02-01 00:00:00|\n",
            "|     G|2024-02-01 00:00:00|\n",
            "|     I|2024-02-01 00:00:00|\n",
            "|     H|2024-02-01 00:00:00|\n",
            "|     K|2024-02-02 00:00:00|\n",
            "|     F|2024-02-02 00:00:00|\n",
            "|     E|2024-02-02 00:00:00|\n",
            "|     B|2024-02-02 00:00:00|\n",
            "|     D|2024-02-02 00:00:00|\n",
            "|     C|2024-02-02 00:00:00|\n",
            "|     J|2024-02-02 00:00:00|\n",
            "|     A|2024-02-02 00:00:00|\n",
            "|     G|2024-02-02 00:00:00|\n",
            "+------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+-------------------+----------+\n",
            "|sensor|                day|max_energy|\n",
            "+------+-------------------+----------+\n",
            "|     A|2024-02-01 00:00:00|     658.6|\n",
            "|     A|2024-02-02 00:00:00|     663.4|\n",
            "|     A|2024-02-03 00:00:00|      NULL|\n",
            "|     A|2024-02-04 00:00:00|      NULL|\n",
            "|     A|2024-02-05 00:00:00|      NULL|\n",
            "|     A|2024-02-06 00:00:00|      NULL|\n",
            "|     A|2024-02-07 00:00:00|      NULL|\n",
            "|     A|2024-02-08 00:00:00|      NULL|\n",
            "|     A|2024-02-09 00:00:00|     712.5|\n",
            "|     A|2024-02-10 00:00:00|     719.9|\n",
            "|     A|2024-02-11 00:00:00|     726.3|\n",
            "|     A|2024-02-12 00:00:00|     733.0|\n",
            "|     A|2024-02-13 00:00:00|     739.8|\n",
            "|     A|2024-02-14 00:00:00|     744.8|\n",
            "|     A|2024-02-15 00:00:00|     749.1|\n",
            "|     A|2024-02-16 00:00:00|     751.0|\n",
            "|     A|2024-02-17 00:00:00|      NULL|\n",
            "|     A|2024-02-18 00:00:00|     763.3|\n",
            "|     A|2024-02-19 00:00:00|     769.0|\n",
            "|     A|2024-02-20 00:00:00|     773.3|\n",
            "+------+-------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+-------------------+-----------------+\n",
            "|sensor|                day|       max_energy|\n",
            "+------+-------------------+-----------------+\n",
            "|     A|2024-02-01 00:00:00|            658.6|\n",
            "|     A|2024-02-02 00:00:00|            663.4|\n",
            "|     A|2024-02-03 00:00:00|670.4142857142857|\n",
            "|     A|2024-02-04 00:00:00|677.4285714285714|\n",
            "|     A|2024-02-05 00:00:00|684.4428571428572|\n",
            "|     A|2024-02-06 00:00:00|691.4571428571428|\n",
            "|     A|2024-02-07 00:00:00|698.4714285714285|\n",
            "|     A|2024-02-08 00:00:00|705.4857142857143|\n",
            "|     A|2024-02-09 00:00:00|            712.5|\n",
            "|     A|2024-02-10 00:00:00|            719.9|\n",
            "|     A|2024-02-11 00:00:00|            726.3|\n",
            "|     A|2024-02-12 00:00:00|            733.0|\n",
            "|     A|2024-02-13 00:00:00|            739.8|\n",
            "|     A|2024-02-14 00:00:00|            744.8|\n",
            "|     A|2024-02-15 00:00:00|            749.1|\n",
            "|     A|2024-02-16 00:00:00|            751.0|\n",
            "|     A|2024-02-17 00:00:00|           757.15|\n",
            "|     A|2024-02-18 00:00:00|            763.3|\n",
            "|     A|2024-02-19 00:00:00|            769.0|\n",
            "|     A|2024-02-20 00:00:00|            773.3|\n",
            "+------+-------------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}